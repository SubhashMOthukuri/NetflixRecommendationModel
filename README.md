# Production ML Data Pipeline - Complete Guide

**End-to-end data pipeline from Kafka â†’ Bronze â†’ Silver â†’ Gold (Feature Store)**

This repository contains a production-grade ML data pipeline following Netflix/Uber standards, implementing the Medallion Architecture (Bronze/Silver/Gold) with comprehensive feature engineering, validation, monitoring, and feature store integration.

---

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Kafka     â”‚  â† Events from producers
â”‚   Topic      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ (Spark Structured Streaming)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      BRONZE LAYER                   â”‚
â”‚  Raw, validated, PII-scrubbed data  â”‚
â”‚  Partitioned by: dt, hr             â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ (Batch Processing)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      SILVER LAYER                   â”‚
â”‚  Cleaned, enriched, normalized data â”‚
â”‚  Partitioned by: event_date, event_type â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ (Feature Engineering)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      GOLD LAYER                     â”‚
â”‚  ML-ready features                  â”‚
â”‚  Partitioned by: feature_date, feature_type â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ (Feast Feature Store)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      FEAST                          â”‚
â”‚  Offline Store (Parquet/S3)         â”‚
â”‚  Online Store (Redis)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ spark_config.yaml          # Spark and storage configuration
â”‚   â”œâ”€â”€ kafka.yaml                 # Kafka configuration
â”‚   â””â”€â”€ feast_config.yaml          # Feast feature store configuration
â”‚
â”œâ”€â”€ data_streaming/
â”‚   â”œâ”€â”€ bronze_ingestion/          # Bronze layer processing
â”‚   â”‚   â”œâ”€â”€ core/                 # Core infrastructure (Spark, Kafka)
â”‚   â”‚   â”œâ”€â”€ transform/            # Transformations (normalization, deduplication)
â”‚   â”‚   â”œâ”€â”€ validation/           # Validation (data quality, PII scrubbing)
â”‚   â”‚   â”œâ”€â”€ storage/              # Storage (writers, checkpointing)
â”‚   â”‚   â”œâ”€â”€ observability/        # Monitoring (metrics, alerting)
â”‚   â”‚   â””â”€â”€ jobs/                 # Job orchestration
â”‚   â”‚
â”‚   â”œâ”€â”€ silver_processing/        # Silver layer processing
â”‚   â”‚   â”œâ”€â”€ core/                 # Core (bronze reader)
â”‚   â”‚   â”œâ”€â”€ transform/             # Transformations (flatten, normalize, type cast)
â”‚   â”‚   â”œâ”€â”€ enrichment/           # Enrichment (joins with lookup tables)
â”‚   â”‚   â”œâ”€â”€ validation/           # Validation (quality, schema enforcement)
â”‚   â”‚   â”œâ”€â”€ storage/              # Storage (silver writer, partition tracker)
â”‚   â”‚   â”œâ”€â”€ observability/        # Monitoring (metrics, alerting)
â”‚   â”‚   â”œâ”€â”€ error_handling/       # Error handling (DLQ)
â”‚   â”‚   â””â”€â”€ jobs/                 # Job orchestration
â”‚   â”‚
â”‚   â””â”€â”€ gold_processing/          # Gold layer processing
â”‚       â”œâ”€â”€ core/                 # Core (silver reader, Feast client)
â”‚       â”œâ”€â”€ feature_engineering/ # Feature engineering (user, item, session, etc.)
â”‚       â”œâ”€â”€ validation/           # Validation (quality checker, schema registry)
â”‚       â”œâ”€â”€ storage/              # Storage (gold writer)
â”‚       â”œâ”€â”€ monitoring/           # Monitoring (metrics, feature monitoring)
â”‚       â””â”€â”€ jobs/                 # Job orchestration (feature job, backfill)
â”‚
â”œâ”€â”€ schemas/                       # Schema definitions
â”‚   â”œâ”€â”€ bronze_schema/            # Bronze layer schemas
â”‚   â”œâ”€â”€ silver_schema/            # Silver layer schemas
â”‚   â””â”€â”€ kafka_schema/             # Kafka event schemas
â”‚
â”œâ”€â”€ libs/                          # Shared libraries
â”‚   â”œâ”€â”€ logger.py                 # Logging utilities
â”‚   â”œâ”€â”€ exceptions.py             # Custom exceptions
â”‚   â””â”€â”€ config_loader.py          # Configuration loader
â”‚
â”œâ”€â”€ services/                      # Producer services
â”‚   â”œâ”€â”€ producer_service.py       # Event producer service
â”‚   â””â”€â”€ producer_main.py          # Producer entry point
â”‚
â”œâ”€â”€ scripts/                       # Utility scripts
â”‚   â””â”€â”€ create_bucket_aws.py     # S3 bucket creation
â”‚
â””â”€â”€ infra/                         # Infrastructure
    â””â”€â”€ docker-compose.yaml       # Docker services (Kafka, MinIO, etc.)
```

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- Java 11+ (for Spark)
- Docker (for Kafka, MinIO)
- Spark 3.5.0

### Installation

```bash
# Install dependencies
pip install -r requirements.txt

# Start infrastructure (Kafka, MinIO)
docker-compose -f infra/docker-compose.yaml up -d

# Create S3 buckets (MinIO)
python scripts/create_bucket_aws.py
```

### Run Pipeline

```bash
# 1. Start producer (generates events to Kafka)
python services/producer_main.py

# 2. Run bronze ingestion (Kafka â†’ Bronze)
python -m data_streaming.bronze_ingestion.jobs.launchers.job_launcher \
    --topic user_events \
    --environment dev

# 3. Run silver processing (Bronze â†’ Silver)
python -m data_streaming.silver_processing.jobs.launchers.silver_job_launcher \
    --start-date 2024-01-15 \
    --end-date 2024-01-16 \
    --environment dev

# 4. Run gold feature engineering (Silver â†’ Gold)
python -m data_streaming.gold_processing.jobs.launchers.gold_job_launcher \
    feature \
    --start-date 2024-01-15 \
    --end-date 2024-01-16 \
    --environment dev
```

---

## ğŸ“š Documentation

### Complete Guides

- **[PRODUCER_TO_KAFKA_GUIDE.md](PRODUCER_TO_KAFKA_GUIDE.md)** - Producer to Kafka pipeline guide
- **[KafkaToSparkToBronze.md](KafkaToSparkToBronze.md)** - Kafka â†’ Spark â†’ Bronze pipeline guide
- **[BRONZE_TO_SILVER_GUIDE.md](BRONZE_TO_SILVER_GUIDE.md)** - Bronze â†’ Silver pipeline guide
- **[SILVER_TO_GOLD_GUIDE.md](SILVER_TO_GOLD_GUIDE.md)** - Silver â†’ Gold pipeline guide
- **[ADVANCED_TOPICS.md](ADVANCED_TOPICS.md)** - Advanced topics and real-time processing

### Cloud Architecture Guides

- **[AZURE_ARCHITECTURE.md](AZURE_ARCHITECTURE.md)** - Production Azure architecture (Event Hub, Databricks, Data Lake Gen2, Purview, Azure ML)
- **[AWS_ARCHITECTURE.md](AWS_ARCHITECTURE.md)** - Production AWS architecture (Kinesis, EMR, S3, Lake Formation, SageMaker)

### Interview Preparation

- **[INTERVIEW_QA.md](INTERVIEW_QA.md)** - 40+ interview questions with answers

---

## ğŸ¯ Pipeline Layers

### **Bronze Layer**
- **Purpose:** Raw, validated data storage
- **Processing:** Kafka â†’ Spark Streaming â†’ Bronze (Parquet)
- **Features:** Schema validation, PII scrubbing, normalization, deduplication
- **Storage:** `s3a://data-lake/bronze/validated/` (partitioned by dt, hr)

### **Silver Layer**
- **Purpose:** Cleaned, enriched, business-ready data
- **Processing:** Bronze â†’ Spark Batch â†’ Silver (Parquet)
- **Features:** Flattening, type casting, normalization, enrichment, validation
- **Storage:** `s3a://data-lake/silver/silver/` (partitioned by event_date, event_type)

### **Gold Layer**
- **Purpose:** ML-ready features for model training and serving
- **Processing:** Silver â†’ Spark Batch â†’ Gold (Parquet) + Feast
- **Features:** User features, item features, session features, statistical, temporal, embeddings
- **Storage:** 
  - Gold: `s3a://data-lake/gold/features/` (partitioned by feature_date, feature_type)
  - Feast: Offline store (Parquet/S3), Online store (Redis)

---

## ğŸ”§ Key Components

### Bronze Layer
- **Kafka Stream Reader** - Reads from Kafka topics
- **Schema Enforcer** - Enforces bronze schema
- **PII Scrubber** - Removes/masks PII data
- **Bronze Validator** - Validates data quality
- **Bronze Writer** - Writes to bronze layer

### Silver Layer
- **Bronze Reader** - Reads from bronze layer
- **Flattener** - Flattens nested structures
- **Type Caster** - Casts data types
- **Normalizer** - Normalizes values
- **Jointer** - Enriches with lookup tables
- **Silver Writer** - Writes to silver layer

### Gold Layer
- **Silver Reader** - Reads from silver layer
- **Feature Engineers** - Computes features (user, item, session, statistical, temporal, embeddings)
- **Feature Quality Checker** - Validates feature quality
- **Feature Schema Registry** - Manages feature schemas
- **Gold Writer** - Writes to gold layer
- **Feast Client** - Writes to Feast feature store

---

## ğŸ“Š Data Flow

### Complete Pipeline Flow

1. **Producer** â†’ Generates events â†’ **Kafka**
2. **Kafka** â†’ Spark Streaming â†’ **Bronze** (raw, validated, PII-scrubbed)
3. **Bronze** â†’ Spark Batch â†’ **Silver** (cleaned, enriched, normalized)
4. **Silver** â†’ Spark Batch â†’ **Gold** (ML-ready features)
5. **Gold** â†’ **Feast** (offline store for training, online store for serving)
6. **Feast** â†’ **ML Model** (training and real-time inference)

---

## ğŸ“ Key Concepts

### Medallion Architecture
- **Bronze:** Raw, validated data (landing zone)
- **Silver:** Cleaned, enriched data (business-ready)
- **Gold:** Feature-engineered data (ML-ready)

### Point-in-Time Correctness
- Features computed as they existed at event timestamp
- Prevents future data leakage in training data
- Critical for accurate model evaluation

### Feature Store (Feast)
- **Offline Store:** Parquet/S3 for training data generation
- **Online Store:** Redis for real-time feature serving (<10ms)
- **Materialization:** Moves features from offline to online

---

## ğŸ“ˆ Monitoring & Observability

### Metrics Tracked
- **Bronze:** Input/output records, validation rates, PII scrubbing stats
- **Silver:** Processing latency, enrichment stats, quality scores
- **Gold:** Feature computation metrics, quality scores, drift detection

### Alerting
- Error rate thresholds
- Data quality score thresholds
- Consumer lag thresholds
- Feature drift detection

---

## ğŸ”’ Security & Compliance

### PII Handling
- **Bronze:** PII scrubbing (hashing, masking)
- **Silver:** PII masking (IP anonymization, geo-location masking)
- **Gold:** No PII in features (already masked)

### GDPR/CCPA Compliance
- PII scrubbing before storage
- Data retention policies
- Audit trails

---

## ğŸš€ Performance Optimizations

### Storage
- **Parquet format** (columnar, compressed)
- **Snappy compression** (fast, good ratio)
- **Partitioning** (by date/hour/type for efficient queries)
- **File size optimization** (128MB-1GB per file)

### Processing
- **Adaptive Query Execution (AQE)** - Automatic optimization
- **Broadcast joins** - For small lookup tables
- **Partition pruning** - Only reads relevant partitions
- **Coalesce/repartition** - Optimizes file sizes

---

## ğŸ“ Configuration

### Config Files
- `config/spark_config.yaml` - Spark settings, storage paths
- `config/kafka.yaml` - Kafka broker and topic settings
- `config/feast_config.yaml` - Feast feature store settings

### Environment Variables
- `JAVA_HOME` - Java installation path
- `SPARK_HOME` - Spark installation path (optional)

---

## ğŸ§ª Testing

### Run Tests
```bash
# Run all tests
pytest tests/

# Run specific test
pytest tests/test_bronze_ingestion.py
```

---

## ğŸ“– Interview Preparation

See **[INTERVIEW_QA.md](INTERVIEW_QA.md)** for 40+ interview questions covering:
- Bronze â†’ Silver â†’ Gold pipeline
- Point-in-time correctness
- Feature engineering
- Feature store (Feast)
- Feature drift detection
- And more...

---

## ğŸ› ï¸ Troubleshooting

### Common Issues

**Issue:** Java gateway process exited
- **Solution:** Set `JAVA_HOME` environment variable

**Issue:** Kafka connection failed
- **Solution:** Check Kafka is running: `docker-compose ps`

**Issue:** S3/MinIO connection failed
- **Solution:** Check MinIO is running and credentials are correct

---

## ğŸ“š Additional Resources

- [Apache Spark Documentation](https://spark.apache.org/docs/latest/)
- [Feast Documentation](https://docs.feast.dev/)
- [Kafka Documentation](https://kafka.apache.org/documentation/)

---

## ğŸ¤ Contributing

This is a production-grade ML data pipeline implementation. All components follow Netflix/Uber standards for:
- Error handling
- Logging
- Monitoring
- Scalability
- Maintainability

---

## ğŸ“„ License

This project is for educational purposes and interview preparation.

---

## âœ… Summary

**Complete Production ML Data Pipeline:**
- âœ… Kafka â†’ Bronze (streaming ingestion)
- âœ… Bronze â†’ Silver (batch transformation)
- âœ… Silver â†’ Gold (feature engineering)
- âœ… Gold â†’ Feast (feature store)
- âœ… Comprehensive monitoring and observability
- âœ… Production-grade error handling
- âœ… Point-in-time correctness support
- âœ… Feature quality validation
- âœ… Feature drift detection

**Ready for:** Production deployment, ML model training, real-time feature serving

---

**Built with â¤ï¸ following Netflix/Uber production standards**
